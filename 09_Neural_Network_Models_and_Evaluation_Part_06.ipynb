{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48631b40-d410-4ac9-be3d-74b6e1a67d0e",
   "metadata": {},
   "source": [
    "## TabNet and Transformer-Based Models for Tabular Data - Part 06\n",
    "\n",
    "+ TabNet and Transformer-based models are advanced architectures designed to handle tabular data more effectively than traditional neural networks.\n",
    "+ They utilize attention mechanisms and novel architectures to capture complex patterns in the data, often leading to improved performance in many machine learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff978728-8e80-468d-9c17-4e2dd77b09a4",
   "metadata": {},
   "source": [
    "**1. TabNet: An Advanced Model for Tabular Data**\n",
    "\n",
    "+ TabNet is a deep learning model specifically designed for tabular data.\n",
    "+ Developed by Google Research, it leverages a self-supervised learning approach and uses sequential attention mechanisms to select the most relevant features for each decision step, providing interpretability while maintaining high accuracy.\n",
    "\n",
    "**Key Features of TabNet:**\n",
    "\n",
    "+ `Attention Mechanism`: TabNet uses a novel sparse attention mechanism that allows the model to select which features to focus on at each decision step, mimicking the decision-making process of an expert.\n",
    "+ `Interpretable Model`: The attention mechanism enables interpretability by showing which features the model is focusing on when making a prediction.\n",
    "+ `Efficient Training`: TabNet uses efficient architecture for faster training on tabular data while maintaining accuracy.\n",
    "+ `Combines Supervised and Self-Supervised Learning`: It supports both types of learning, making it flexible for various tasks.\n",
    "\n",
    "**How TabNet Works:**\n",
    "\n",
    "+ `Feature Selection`: At each decision step, TabNet selects a subset of the input features using a learnable mask, which helps in focusing on the most important features for the prediction.\n",
    "+ `Decision Steps`: The model is composed of multiple decision steps, where each step builds on the previous one, allowing the model to capture complex patterns in the data.\n",
    "+ `Sparse Feature Masking`: Only a fraction of features is selected at each decision step, promoting interpretability and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "558c56d8-dc8d-4a16-9fed-8cfaa853f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55ada7ac-8750-4ead-a4a5-7cf592835ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load and process the data\n",
    "# Load your dataset\n",
    "data = pd.read_csv('no_missing_values_customer_data.csv')\n",
    "\n",
    "# Convert the target variable 'Churn' to numeric\n",
    "data['Churn'] = data['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Encode categorical variables using Label Encoding\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    if col != 'customerID':\n",
    "        data[col] = LabelEncoder().fit_transform(data[col])\n",
    "\n",
    "# Separate features and target\n",
    "features = data.drop(['Churn', 'customerID'], axis=1).values\n",
    "target = data['Churn'].values\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd188966-5d8d-4379-95a9-74e3ba623ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faiz Salam\\AnacondaNavigator\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55888 | val_0_accuracy: 0.72534 |  0:00:02s\n",
      "epoch 1  | loss: 0.46961 | val_0_accuracy: 0.74592 |  0:00:04s\n",
      "epoch 2  | loss: 0.45274 | val_0_accuracy: 0.78353 |  0:00:06s\n",
      "epoch 3  | loss: 0.45175 | val_0_accuracy: 0.79063 |  0:00:07s\n",
      "epoch 4  | loss: 0.43802 | val_0_accuracy: 0.78282 |  0:00:09s\n",
      "epoch 5  | loss: 0.43967 | val_0_accuracy: 0.79063 |  0:00:11s\n",
      "epoch 6  | loss: 0.43142 | val_0_accuracy: 0.78992 |  0:00:13s\n",
      "epoch 7  | loss: 0.43401 | val_0_accuracy: 0.79702 |  0:00:15s\n",
      "epoch 8  | loss: 0.43634 | val_0_accuracy: 0.79844 |  0:00:17s\n",
      "epoch 9  | loss: 0.42908 | val_0_accuracy: 0.79915 |  0:00:19s\n",
      "epoch 10 | loss: 0.4316  | val_0_accuracy: 0.79276 |  0:00:21s\n",
      "epoch 11 | loss: 0.43058 | val_0_accuracy: 0.79418 |  0:00:22s\n",
      "epoch 12 | loss: 0.42625 | val_0_accuracy: 0.78992 |  0:00:24s\n",
      "epoch 13 | loss: 0.42809 | val_0_accuracy: 0.79844 |  0:00:26s\n",
      "epoch 14 | loss: 0.42762 | val_0_accuracy: 0.79347 |  0:00:28s\n",
      "epoch 15 | loss: 0.42729 | val_0_accuracy: 0.80412 |  0:00:30s\n",
      "epoch 16 | loss: 0.42554 | val_0_accuracy: 0.80554 |  0:00:31s\n",
      "epoch 17 | loss: 0.42725 | val_0_accuracy: 0.79702 |  0:00:33s\n",
      "epoch 18 | loss: 0.42545 | val_0_accuracy: 0.80412 |  0:00:35s\n",
      "epoch 19 | loss: 0.41878 | val_0_accuracy: 0.8027  |  0:00:37s\n",
      "epoch 20 | loss: 0.41969 | val_0_accuracy: 0.80412 |  0:00:39s\n",
      "epoch 21 | loss: 0.41934 | val_0_accuracy: 0.79702 |  0:00:41s\n",
      "epoch 22 | loss: 0.41924 | val_0_accuracy: 0.79986 |  0:00:43s\n",
      "epoch 23 | loss: 0.41547 | val_0_accuracy: 0.80341 |  0:00:45s\n",
      "epoch 24 | loss: 0.41585 | val_0_accuracy: 0.8105  |  0:00:47s\n",
      "epoch 25 | loss: 0.41335 | val_0_accuracy: 0.80128 |  0:00:49s\n",
      "epoch 26 | loss: 0.41472 | val_0_accuracy: 0.80554 |  0:00:51s\n",
      "epoch 27 | loss: 0.41942 | val_0_accuracy: 0.79915 |  0:00:52s\n",
      "epoch 28 | loss: 0.41641 | val_0_accuracy: 0.79986 |  0:00:54s\n",
      "epoch 29 | loss: 0.42032 | val_0_accuracy: 0.79702 |  0:00:56s\n",
      "epoch 30 | loss: 0.42277 | val_0_accuracy: 0.80554 |  0:00:58s\n",
      "epoch 31 | loss: 0.41502 | val_0_accuracy: 0.80199 |  0:01:00s\n",
      "epoch 32 | loss: 0.41906 | val_0_accuracy: 0.8105  |  0:01:02s\n",
      "epoch 33 | loss: 0.41656 | val_0_accuracy: 0.79915 |  0:01:04s\n",
      "epoch 34 | loss: 0.41902 | val_0_accuracy: 0.79844 |  0:01:06s\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_accuracy = 0.8105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faiz Salam\\AnacondaNavigator\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for TabNet:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1036\n",
      "           1       0.68      0.55      0.60       373\n",
      "\n",
      "    accuracy                           0.81      1409\n",
      "   macro avg       0.76      0.73      0.74      1409\n",
      "weighted avg       0.80      0.81      0.80      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## model development\n",
    "# Initialize TabNetClassifier\n",
    "tabnet_clf = TabNetClassifier()\n",
    "\n",
    "# Train TabNet model\n",
    "tabnet_clf.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric=['accuracy'],\n",
    "    max_epochs=100,\n",
    "    patience=10,\n",
    "    batch_size=256,\n",
    "    virtual_batch_size=128\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = tabnet_clf.predict(X_test)\n",
    "print(\"Classification Report for TabNet:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66581d-ccad-484d-bb27-55a19e9963c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
